{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a9dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed code_famille_QA.json with 39 items\n",
      "Successfully processed code_famille_QA_2.json with 28 items\n",
      "Successfully processed code_famille_QA_3.json with 25 items\n",
      "Successfully processed code_famille_QA_4.json with 25 items\n",
      "Successfully processed code_famille_QA_5.json with 25 items\n",
      "\n",
      "Successfully processed 5 files and saved 142 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\family_code_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Define the directory containing the JSON files\n",
    "json_dir = Path(\"D:/a_PROJECTS/legal-rag-assistant/Notebooks/data/morocco\")  # Update this path to your actual directory\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "famille_dir = json_dir\n",
    "\n",
    "# Specify the famille code files to concatenate\n",
    "famille_files = [\n",
    "    famille_dir / \"code_famille_QA.json\",\n",
    "    famille_dir / \"code_famille_QA_2.json\",\n",
    "    famille_dir / \"code_famille_QA_3.json\",\n",
    "    famille_dir / \"code_famille_QA_4.json\",\n",
    "    famille_dir / \"code_famille_QA_5.json\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the famille code data\n",
    "all_famille_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in famille_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add code to each item in the list if not already present\n",
    "                    for item in data:\n",
    "                        if 'code' not in item:\n",
    "                            item['code'] = \"code famille 2016\"\n",
    "                    all_famille_data.extend(data)\n",
    "                else:\n",
    "                    # Add code to the single object if not already present\n",
    "                    if 'code' not in data:\n",
    "                        data['code'] = \"code famille 2016\"\n",
    "                    all_famille_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "famille_output_path = famille_dir / \"family_code_data.json\"\n",
    "with open(famille_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_famille_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "famille_question_count = len(all_famille_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in famille_files if f.exists()])} files and saved {famille_question_count} items to {famille_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c21abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed code_penale_QA.json with 37 items\n",
      "Successfully processed code_penale_QA_2.json with 23 items\n",
      "Successfully processed code_penale_QA_3.json with 24 items\n",
      "Successfully processed code_penale_QA_4.json with 25 items\n",
      "Successfully processed code_penale_QA_5.json with 25 items\n",
      "\n",
      "Successfully processed 5 files and saved 134 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\penal_code_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "penal_dir = json_dir\n",
    "\n",
    "# Specify the penal code files to concatenate\n",
    "penal_files = [\n",
    "    penal_dir / \"code_penale_QA.json\",\n",
    "    penal_dir / \"code_penale_QA_2.json\",\n",
    "    penal_dir / \"code_penale_QA_3.json\",\n",
    "    penal_dir / \"code_penale_QA_4.json\",\n",
    "    penal_dir / \"code_penale_QA_5.json\"\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the penal code data\n",
    "all_penal_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in penal_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add data directly without modifying code field\n",
    "                    all_penal_data.extend(data)\n",
    "                else:\n",
    "                    # Add data directly without modifying code field\n",
    "                    all_penal_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "penal_output_path = penal_dir / \"penal_code_data.json\"\n",
    "with open(penal_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_penal_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "penal_question_count = len(all_penal_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in penal_files if f.exists()])} files and saved {penal_question_count} items to {penal_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c190c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed code_contrat-obligation_QA.json with 26 items\n",
      "Successfully processed code_contrat-obligation_QA_2.json with 16 items\n",
      "Successfully processed code_contrat-obligation_QA_3.json with 20 items\n",
      "Successfully processed code_contrat-obligation_QA_4.json with 20 items\n",
      "Successfully processed code_contrat-obligation_QA_5.json with 19 items\n",
      "Successfully processed code_contrat-obligation_QA_6.json with 25 items\n",
      "Successfully processed code_contrat-obligation_QA_7.json with 20 items\n",
      "\n",
      "Successfully processed 7 files and saved 146 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\contrat_obligation_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "contrat_dir = json_dir\n",
    "\n",
    "# Specify the contrat-obligation code files to concatenate\n",
    "contrat_files = [\n",
    "    contrat_dir / \"code_contrat-obligation_QA.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_2.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_3.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_4.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_5.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_6.json\",\n",
    "    contrat_dir / \"code_contrat-obligation_QA_7.json\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the contrat-obligation code data\n",
    "all_contrat_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in contrat_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add code to each item in the list if not already present\n",
    "                    for item in data:\n",
    "                        if 'code' not in item:\n",
    "                            item['code'] = \"code contrat-obligation\"\n",
    "                    all_contrat_data.extend(data)\n",
    "                else:\n",
    "                    # Add code to the single object if not already present\n",
    "                    if 'code' not in data:\n",
    "                        data['code'] = \"code contrat-obligation\"\n",
    "                    all_contrat_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "contrat_output_path = contrat_dir / \"contrat_obligation_data.json\"\n",
    "with open(contrat_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_contrat_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "contrat_question_count = len(all_contrat_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in contrat_files if f.exists()])} files and saved {contrat_question_count} items to {contrat_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "973a4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed code_commerce_QA.json with 24 items\n",
      "Successfully processed code_commerce_QA_2.json with 20 items\n",
      "Successfully processed code_commerce_QA_3.json with 25 items\n",
      "Successfully processed code_commerce_QA_4.json with 25 items\n",
      "Successfully processed code_commerce_QA_5.json with 25 items\n",
      "Successfully processed code_commerce_QA_6.json with 25 items\n",
      "\n",
      "Successfully processed 6 files and saved 144 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\commerce_code_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "commerce_dir = json_dir\n",
    "\n",
    "# Specify the commerce code files to concatenate\n",
    "commerce_files = [\n",
    "    commerce_dir / \"code_commerce_QA.json\",\n",
    "    commerce_dir / \"code_commerce_QA_2.json\",\n",
    "    commerce_dir / \"code_commerce_QA_3.json\",\n",
    "    commerce_dir / \"code_commerce_QA_4.json\",\n",
    "    commerce_dir / \"code_commerce_QA_5.json\",\n",
    "    commerce_dir / \"code_commerce_QA_6.json\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the commerce code data\n",
    "all_commerce_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in commerce_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add code to each item in the list if not already present\n",
    "                    for item in data:\n",
    "                        if 'code' not in item:\n",
    "                            item['code'] = \"code commerce\"\n",
    "                    all_commerce_data.extend(data)\n",
    "                else:\n",
    "                    # Add code to the single object if not already present\n",
    "                    if 'code' not in data:\n",
    "                        data['code'] = \"code commerce\"\n",
    "                    all_commerce_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "commerce_output_path = commerce_dir / \"commerce_code_data.json\"\n",
    "with open(commerce_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_commerce_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "commerce_question_count = len(all_commerce_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in commerce_files if f.exists()])} files and saved {commerce_question_count} items to {commerce_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9af2895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed constitution_mar_QA.json with 25 items\n",
      "Successfully processed constitution_mar_QA_2.json with 25 items\n",
      "Successfully processed constitution_mar_QA_3.json with 25 items\n",
      "Successfully processed constitution_mar_QA_4.json with 20 items\n",
      "Successfully processed constitution_mar_QA_5.json with 25 items\n",
      "Successfully processed constitution_mar_QA_6.json with 25 items\n",
      "Successfully processed constitution_mar_QA_7.json with 25 items\n",
      "\n",
      "Successfully processed 7 files and saved 170 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\constitution_mar_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "constitution_dir = json_dir\n",
    "\n",
    "# Specify the Moroccan constitution files to concatenate\n",
    "constitution_files = [\n",
    "    constitution_dir / \"constitution_mar_QA.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_2.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_3.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_4.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_5.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_6.json\",\n",
    "    constitution_dir / \"constitution_mar_QA_7.json\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the constitution data\n",
    "all_constitution_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in constitution_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add code to each item in the list if not already present\n",
    "                    for item in data:\n",
    "                        if 'code' not in item:\n",
    "                            item['code'] = \"constitution marocaine 2011\"\n",
    "                    all_constitution_data.extend(data)\n",
    "                else:\n",
    "                    # Add code to the single object if not already present\n",
    "                    if 'code' not in data:\n",
    "                        data['code'] = \"constitution marocaine 2011\"\n",
    "                    all_constitution_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "constitution_output_path = constitution_dir / \"constitution_mar_data.json\"\n",
    "with open(constitution_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_constitution_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "constitution_question_count = len(all_constitution_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in constitution_files if f.exists()])} files and saved {constitution_question_count} items to {constitution_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eb21600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed code_travail_QA.json with 23 items\n",
      "Successfully processed code_travail_QA_2.json with 25 items\n",
      "Successfully processed code_travail_QA_3.json with 24 items\n",
      "Successfully processed code_travail_QA_4.json with 24 items\n",
      "Successfully processed code_travail_QA_5.json with 25 items\n",
      "Successfully processed code_travail_QA_6.json with 25 items\n",
      "\n",
      "Successfully processed 6 files and saved 146 items to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\travail_code_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path (using the existing json_dir)\n",
    "travail_dir = json_dir\n",
    "\n",
    "# Specify the code_travail files to concatenate\n",
    "travail_files = [\n",
    "    travail_dir / \"code_travail_QA.json\",\n",
    "    travail_dir / \"code_travail_QA_2.json\",\n",
    "    travail_dir / \"code_travail_QA_3.json\",\n",
    "    travail_dir / \"code_travail_QA_4.json\",\n",
    "    travail_dir / \"code_travail_QA_5.json\",\n",
    "    travail_dir / \"code_travail_QA_6.json\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store all the travail code data\n",
    "all_travail_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in travail_files:\n",
    "    # Check if file exists before trying to open it\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    # Add code to each item in the list if not already present\n",
    "                    for item in data:\n",
    "                        if 'code' not in item:\n",
    "                            item['code'] = \"code travail\"\n",
    "                    all_travail_data.extend(data)\n",
    "                else:\n",
    "                    # Add code to the single object if not already present\n",
    "                    if 'code' not in data:\n",
    "                        data['code'] = \"code travail\"\n",
    "                    all_travail_data.append(data)\n",
    "                \n",
    "                print(f\"Successfully processed {file_path.name} with {len(data) if isinstance(data, list) else 1} items\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "\n",
    "# Save the concatenated data to a new file\n",
    "travail_output_path = travail_dir / \"travail_code_data.json\"\n",
    "with open(travail_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_travail_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "travail_question_count = len(all_travail_data)\n",
    "print(f\"\\nSuccessfully processed {len([f for f in travail_files if f.exists()])} files and saved {travail_question_count} items to {travail_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9a2b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully combined all code datasets into a single file with 882 QA pairs\n",
      "\n",
      "Distribution by code:\n",
      "- code famille 2016: 142 items (16.1%)\n",
      "- DAHIR FORMANT CODE DES OBLIGATIONS ET DES CONTRATS: 146 items (16.55%)\n",
      "- code de commerce 2019: 144 items (16.33%)\n",
      "- code penale 2018: 134 items (15.19%)\n",
      "- Code du Travail: 146 items (16.55%)\n",
      "- Constitution du Maroc 2011: 170 items (19.27%)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Combine all the individual code datasets into a single list for training\n",
    "all_legal_data = []\n",
    "\n",
    "# Add data from each source\n",
    "all_legal_data.extend(all_famille_data)      # Family code data\n",
    "all_legal_data.extend(all_penal_data)        # Penal code data\n",
    "all_legal_data.extend(all_contrat_data)      # Contract/obligation code data\n",
    "all_legal_data.extend(all_commerce_data)     # Commerce code data\n",
    "all_legal_data.extend(all_constitution_data) # Constitution data\n",
    "all_legal_data.extend(all_travail_data)      # Labor code data\n",
    "\n",
    "# Shuffle the data for better training\n",
    "random.shuffle(all_legal_data)\n",
    "\n",
    "# Save the combined dataset to a single file\n",
    "combined_output_path = json_dir / \"train_legal_data.json\"\n",
    "with open(combined_output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_legal_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print summary of the combined dataset\n",
    "total_qa_count = len(all_legal_data)\n",
    "codes_distribution = {}\n",
    "for item in all_legal_data:\n",
    "    code = item.get('code', 'Unknown')\n",
    "    codes_distribution[code] = codes_distribution.get(code, 0) + 1\n",
    "\n",
    "print(f\"\\nSuccessfully combined all code datasets into a single file with {total_qa_count} QA pairs\")\n",
    "print(\"\\nDistribution by code:\")\n",
    "for code, count in codes_distribution.items():\n",
    "    print(f\"- {code}: {count} items ({round(count/total_qa_count*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9dd6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully combined all evaluation datasets into a single file with 151 QA pairs\n",
      "\n",
      "Distribution by code:\n",
      "- code famille 2016: 6 items (3.97%)\n",
      "- code penale 2018: 11 items (7.28%)\n",
      "- Constitution du Maroc 2011: 14 items (9.27%)\n",
      "- Code du Travail: 67 items (44.37%)\n",
      "- code de commerce 2019: 23 items (15.23%)\n",
      "- DAHIR FORMANT CODE DES OBLIGATIONS ET DES CONTRATS: 13 items (8.61%)\n",
      "- Combinaison implicite / Information non directement présente: 1 items (0.66%)\n",
      "- Combinaison Code de Commerce / Code du Travail (partiel): 1 items (0.66%)\n",
      "- Unknown: 15 items (9.93%)\n"
     ]
    }
   ],
   "source": [
    "# Combine the three evaluation datasets into a single evaluation file\n",
    "# Define the paths for each evaluation part\n",
    "eval_part1_path = json_dir / \"evaluation_part1.json\"\n",
    "eval_part2_path = json_dir / \"evaluation_part2.json\"\n",
    "eval_part3_path = json_dir / \"evaluation_part3.json\"\n",
    "eval_part4_path = json_dir / \"evaluation_part4.json\"\n",
    "eval_part5_path = json_dir / \"evaluation_part5.json\"\n",
    "eval_part6_path = json_dir / \"evaluation_part6.json\"\n",
    "eval_part7_path = json_dir / \"evaluation_part7.json\"\n",
    "eval_part8_path = json_dir / \"evaluation_part8.json\"\n",
    "\n",
    "# Define the output path for combined evaluation data\n",
    "eval_combined_path = json_dir / \"eval_legal_data.json\"\n",
    "\n",
    "# Initialize a list to store all evaluation data\n",
    "all_eval_data = []\n",
    "\n",
    "# Function to load and process each evaluation file\n",
    "def load_eval_data(file_path):\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                # Check if it's a list or a single object\n",
    "                if isinstance(data, list):\n",
    "                    return data\n",
    "                else:\n",
    "                    return [data]\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON from {file_path.name}\")\n",
    "                return []\n",
    "    else:\n",
    "        print(f\"Warning: File {file_path.name} not found\")\n",
    "        return []\n",
    "\n",
    "# Load data from each evaluation part\n",
    "eval_part1_data = load_eval_data(eval_part1_path)\n",
    "eval_part2_data = load_eval_data(eval_part2_path)\n",
    "eval_part3_data = load_eval_data(eval_part3_path)\n",
    "eval_part4_data = load_eval_data(eval_part4_path)\n",
    "eval_part5_data = load_eval_data(eval_part5_path)\n",
    "eval_part6_data = load_eval_data(eval_part6_path)\n",
    "eval_part7_data = load_eval_data(eval_part7_path)\n",
    "eval_part8_data = load_eval_data(eval_part8_path)\n",
    "\n",
    "# Combine all data\n",
    "all_eval_data.extend(eval_part1_data)\n",
    "all_eval_data.extend(eval_part2_data)\n",
    "all_eval_data.extend(eval_part3_data)\n",
    "all_eval_data.extend(eval_part4_data)\n",
    "all_eval_data.extend(eval_part5_data)\n",
    "all_eval_data.extend(eval_part6_data)\n",
    "all_eval_data.extend(eval_part7_data)\n",
    "all_eval_data.extend(eval_part8_data)\n",
    "\n",
    "# Save the combined dataset to a single file\n",
    "with open(eval_combined_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_eval_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print summary of the combined evaluation dataset\n",
    "eval_total_count = len(all_eval_data)\n",
    "eval_codes_distribution = {}\n",
    "for item in all_eval_data:\n",
    "    code = item.get('code', 'Unknown')\n",
    "    eval_codes_distribution[code] = eval_codes_distribution.get(code, 0) + 1\n",
    "\n",
    "print(f\"\\nSuccessfully combined all evaluation datasets into a single file with {eval_total_count} QA pairs\")\n",
    "print(\"\\nDistribution by code:\")\n",
    "for code, count in eval_codes_distribution.items():\n",
    "    print(f\"- {code}: {count} items ({round(count/eval_total_count*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58eb0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed evaluation dataset saved to D:\\a_PROJECTS\\legal-rag-assistant\\Notebooks\\data\\morocco\\eval_legal_data.json with 151 QA pairs\n",
      "\n",
      "Updated distribution by code:\n",
      "- code famille 2016: 7 items (4.64%)\n",
      "- code penale 2018: 15 items (9.93%)\n",
      "- Constitution du Maroc 2011: 16 items (10.6%)\n",
      "- Code du Travail: 72 items (47.68%)\n",
      "- code de commerce 2019: 24 items (15.89%)\n",
      "- DAHIR FORMANT CODE DES OBLIGATIONS ET DES CONTRATS: 14 items (9.27%)\n",
      "- Combinaison implicite / Information non directement présente: 1 items (0.66%)\n",
      "- Combinaison Code de Commerce / Code du Travail (partiel): 1 items (0.66%)\n",
      "- Combinaison Code du Travail / Constitution du Maroc 2011: 1 items (0.66%)\n"
     ]
    }
   ],
   "source": [
    "# Check the evaluation data for inconsistencies in 'code' field and fix them\n",
    "fixed_eval_data = []\n",
    "\n",
    "for item in all_eval_data:\n",
    "    fixed_item = item.copy()\n",
    "    \n",
    "    # Check if 'code_source' exists but 'code' doesn't\n",
    "    if 'code_source' in item and 'code' not in item:\n",
    "        fixed_item['code'] = item['code_source']\n",
    "        del fixed_item['code_source']\n",
    "    \n",
    "    # Add the fixed item to our new list\n",
    "    fixed_eval_data.append(fixed_item)\n",
    "\n",
    "# Save the fixed evaluation dataset\n",
    "fixed_eval_combined_path = json_dir / \"eval_legal_data.json\"\n",
    "with open(fixed_eval_combined_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(fixed_eval_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print the updated distribution\n",
    "fixed_codes_distribution = {}\n",
    "for item in fixed_eval_data:\n",
    "    code = item.get('code', 'Unknown')\n",
    "    fixed_codes_distribution[code] = fixed_codes_distribution.get(code, 0) + 1\n",
    "\n",
    "print(f\"\\nFixed evaluation dataset saved to {fixed_eval_combined_path} with {len(fixed_eval_data)} QA pairs\")\n",
    "print(\"\\nUpdated distribution by code:\")\n",
    "for code, count in fixed_codes_distribution.items():\n",
    "    print(f\"- {code}: {count} items ({round(count/len(fixed_eval_data)*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766653d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfcd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
